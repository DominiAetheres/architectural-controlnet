{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba92ab56",
   "metadata": {},
   "source": [
    "### 1. Read in target pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90224fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def read_images(directory: Path = Path(\"./\")) -> list[Path]:\n",
    "    \"\"\"\n",
    "    Return a sorted list of all file paths in `directory` (non-recursive)\n",
    "    excluding any .ipynb files.\n",
    "    \"\"\"\n",
    "    directory = directory.resolve()\n",
    "    paths = [\n",
    "        p for p in directory.iterdir()\n",
    "        if p.is_file() and p.suffix.lower() != \".ipynb\"\n",
    "    ]\n",
    "    return sorted(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd54e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = read_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e2041",
   "metadata": {},
   "source": [
    "### 2. Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdd5fef",
   "metadata": {},
   "source": [
    "Resize to 512x512 for ControlNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d90d2081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78ca1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_512(img_path: str, interpolation=cv2.INTER_AREA):\n",
    "    \"\"\"\n",
    "    Load an image, pad it to a square canvas (keeping the original centered),\n",
    "    then resize to 512x512.\n",
    "\n",
    "    Args:\n",
    "        img_path (str): Path to the input image.\n",
    "        interpolation (int): OpenCV interpolation flag:\n",
    "            - cv2.INTER_AREA for downscaling,\n",
    "            - cv2.INTER_CUBIC / cv2.INTER_LINEAR for upscaling.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The 512x512 BGR image.\n",
    "    \"\"\"\n",
    "    # Load image (preserve alpha if present)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Could not load image at '{img_path}'\")\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    # Compute padding to make square\n",
    "    if h == w:\n",
    "        square = img\n",
    "    else:\n",
    "        # Determine new square size and padding amounts\n",
    "        size = max(h, w)\n",
    "        pad_vert = (size - h) // 2\n",
    "        pad_horiz = (size - w) // 2\n",
    "\n",
    "        # Padding: top, bottom, left, right\n",
    "        top    = pad_vert\n",
    "        bottom = size - h - pad_vert\n",
    "        left   = pad_horiz\n",
    "        right  = size - w - pad_horiz\n",
    "\n",
    "        # If the image has alpha channel, pad with (0,0,0,0), otherwise with black\n",
    "        if img.shape[2] == 4:\n",
    "            border_color = [0, 0, 0, 0]\n",
    "        else:\n",
    "            border_color = [0, 0, 0]\n",
    "\n",
    "        square = cv2.copyMakeBorder(\n",
    "            img,\n",
    "            top, bottom, left, right,\n",
    "            borderType=cv2.BORDER_CONSTANT,\n",
    "            value=border_color\n",
    "        )\n",
    "\n",
    "    # Resize square to 512x512\n",
    "    resized = cv2.resize(square, (512, 512), interpolation=interpolation)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85c6633",
   "metadata": {},
   "source": [
    "Convert to greyscale for input into edge detection code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grayscale(img):\n",
    "    \"\"\"\n",
    "    Convert img to a single-channel grayscale image, handling:\n",
    "     - already gray (HxW)\n",
    "     - BGR (HxWx3)\n",
    "     - BGRA (HxWx4)\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    chans = 1 if img.ndim == 2 else img.shape[2]\n",
    "\n",
    "    if chans == 1:\n",
    "        # already gray\n",
    "        return img\n",
    "    elif chans == 3:\n",
    "        # BGR → GRAY\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    elif chans == 4:\n",
    "        # BGRA → GRAY\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected channel count: {chans}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4818c8",
   "metadata": {},
   "source": [
    "Use CLAHE to boost details such as wood panelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62567b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLAHE(img):\n",
    "    \"\"\"\n",
    "    Use CLAHE to boost contrast in detailed areas of the image.\n",
    "    Standard histogram equalisation is too noisy.\n",
    "    \"\"\"\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "    enhanced = clahe.apply(img)\n",
    "\n",
    "    return enhanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75169424",
   "metadata": {},
   "source": [
    "Perform Prewitt edge detection to create the corresponding training sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56ae57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prewitt_edge_detection(image, threshold):\n",
    "    \"\"\"\n",
    "    Apply Prewitt edge detection to an image.\n",
    "    \n",
    "    Args:\n",
    "        image: numpy array - the input image (grayscale or color)\n",
    "        threshold: int - threshold value for edge detection\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: the processed image as numpy array with Prewitt edges detected\n",
    "    \"\"\"\n",
    "    # Convert to greyscale if needed\n",
    "    if len(image.shape) == 3:\n",
    "        np_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        np_image = image\n",
    "    \n",
    "    # Define masks for Prewitt operator\n",
    "    xkernel = np.array([[1, 0, -1],\n",
    "                        [1, 0, -1],\n",
    "                        [1, 0, -1]])\n",
    "   \n",
    "    ykernel = np.array([[1, 1, 1],\n",
    "                        [0, 0, 0],\n",
    "                        [-1, -1, -1]])\n",
    "   \n",
    "    # Apply convolutions\n",
    "    prewittx = cv2.filter2D(np_image, cv2.CV_64F, xkernel)\n",
    "    prewitty = cv2.filter2D(np_image, cv2.CV_64F, ykernel)\n",
    "    \n",
    "    # Take the magnitude\n",
    "    prewitt = np.sqrt(prewittx ** 2 + prewitty ** 2)\n",
    "    \n",
    "    # Normalize the filtered image to 0-255 range\n",
    "    prewitt = cv2.normalize(prewitt, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "   \n",
    "        \n",
    "    # Apply thresholding\n",
    "    prewitt = (prewitt > threshold) * prewitt\n",
    "    \n",
    "    return prewitt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc9640f",
   "metadata": {},
   "source": [
    "Create the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a99fdf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01.jpg'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(targets[0]).split(\"\\\\\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each image from the image path list\n",
    "# Perform the following steps:\n",
    "#   1. Resize to 512x512 to fit ControlNet\n",
    "#   2. Greyscale\n",
    "#   3. CLAHE to denoise whilst preserving fine details\n",
    "#   4. Prewitt edge detection\n",
    "for image in targets:\n",
    "    resized = to_512(image)\n",
    "    grey = to_grayscale(resized)\n",
    "    enhanced = CLAHE(grey)\n",
    "    edges = prewitt_edge_detection(enhanced, 5)\n",
    "\n",
    "    # turn into sketch\n",
    "    sketch = cv2.bitwise_not(edges)\n",
    "\n",
    "    # file name\n",
    "    filename = str(image).split(\"\\\\\")[-1].replace(\".jpg\", \"\")\n",
    "    \n",
    "    # write input file\n",
    "    cv2.imwrite(f\"./sketch/{filename}.png\", sketch)\n",
    "    # write output target pair\n",
    "    cv2.imwrite(f\"./image/{filename}.png\", resized)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "actual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
